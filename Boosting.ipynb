{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZByBL77uBdhP"
      },
      "source": [
        "## Лабораторная работа 7. Бустинги!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n82rR0CWBdhR"
      },
      "source": [
        "В этой домашке познакомимся с новым методом ансамблирования — бустингом, а также немножко доработаем фичи для предыдущего датасета, чтобы получать лучшее качество на тестовом датасете.\n",
        "\n",
        "Контест https://contest.yandex.ru/contest/40410\n",
        "\n",
        "#### Дискуссия\n",
        "Краеугольными камнями машинлернера являются данные и модели: применили более качественную модель — получили прирост метрик, нашли дополнительные данные или сгенерировали информативные признаки, которые наша модель не может сгенерировать сама — получили прирост метрик. Поскольку мы продолжаем тему ансамблирования, то разберемся с ультимативным методом ансамблирования — бустингом, который до сих пор дает топовые места в табличных соревнованиях и используется в качестве модели верхнего уровня в сложных стэкинговых пайплайнах Яндекса.\n",
        "\n",
        "#### Адаптивный бустинг\n",
        "Первой задачей будет имплементация алгоритма SAMME.R для адаптивного бустинга — последовательного обучения слабых классификаторов с **перевзвешенными** объектами обучающей выборки для уточнения предсказаний именно на примерах с сильно отличающимися от истинных предсказаниями.\n",
        "\n",
        "Наша имплементация будет опираться на авторскую монографию ([ссылка](https://hastie.su.domains/Papers/samme.pdf)).\n",
        "\n",
        "Прочтите оттуда описание алгоритма 4 и используйте следующие подсказки для полноценной имплементации:\n",
        "* В качестве базового классификатора применяйте (и держите в голове при написании кода) `DecisionTreeClassifier` из `sklearn`, т.к. он умеет работать со взвешенными объектами обучающей выборки. В качестве бонусного задания подумайте, как модифицировать нашу реализацию деревьев, чтобы она тоже умела работать с приоритетными объектами. Однако, заметьте, что бустить этим алгоритмом можно не только деревья, но и другие модели, которые могут предсказывать вероятности, например, логистическую регрессию, перцептрон и другие.\n",
        "* Заметьте, что в статье истинные метки классов пересчитаны некоторым нестандартным образом (формула (2) похожа на OneHot, но сглаженный), там это мотивировано вероятностной постановкой задачи. На практике так часто делают, чтобы улучшить протекание градиента в нейросетях или распространение информации в весах бустинга, поскольку неверные предикты не зануляются совсем при пересчете весов.\n",
        "* При подсчете вероятности класса для данного объекта берется сумма скоров, предсказаных базовыми классификаторами, потом перевзвешивается при помощи `softmax`, то есть формула для вероятности принимает вид (подумайте, чему эта формула соответствует при подстановке $h$ через вероятность):\n",
        "$$\n",
        "    P(y_i = k|x_i) = \\frac{\\exp\\left\\{\\frac{1}{K-1}\\sum_{m=1}^Mh_k^{(m)}(x_i)\\right\\}}{\\sum_{k'=1}^K\\exp\\left\\{\\frac{1}{K-1}\\sum_{m=1}^Mh_{k'}^{(m)}(x_i)\\right\\}}\n",
        "$$\n",
        "\n",
        "**1. (1 балл) Сдайте реализацию перевзвешивания в адаптивном бустинге в контест.**\n",
        "\n",
        "**2. (2 балла) Сдайте реализацию обучения классификатора в контест.**\n",
        "\n",
        "**3. (2 балла) Сдайте реализацию предсказания в адаптивном бустинге в контест.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZI6fYifOBdhT"
      },
      "outputs": [],
      "source": [
        "from src import MyAdaBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZ67L9FBdhU"
      },
      "source": [
        "Воспользуемся полюбившейся библиотекой, чтобы смотреть на предсказания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7Bm0GtfhBdhU"
      },
      "outputs": [],
      "source": [
        "!pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ffckUFJOBdhU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "\n",
        "def make_sunny_moons(n_sun=50, n_moons=100, noise=0.0, sun_radius=1.9, theta=None):\n",
        "    X_moons, y_moons = make_moons(n_samples=n_moons, noise=noise, random_state=0xC0FFEE)\n",
        "    if not n_sun:\n",
        "        return X_moons, y_moons\n",
        "\n",
        "    rng = np.random.default_rng(0xC0FFEE)\n",
        "    angles = np.arange(0, 2 * np.pi, 2 * np.pi / n_sun)\n",
        "    X_sun = sun_radius * np.column_stack([np.cos(angles), np.sin(angles)]) + np.array([0.5, 0.25])\n",
        "    X_sun += rng.normal(scale=noise, size=X_sun.shape)\n",
        "    y_sun = 2 * np.ones(n_sun)\n",
        "\n",
        "    X = np.vstack([X_moons, X_sun])\n",
        "    y = np.concatenate([y_moons, y_sun]).astype(int)\n",
        "    X -= X.mean(axis=0)\n",
        "\n",
        "    if theta is None:\n",
        "        theta = np.pi / 4\n",
        "    c, s = np.cos(theta), np.sin(theta)\n",
        "    R = np.array(((c, -s), (s, c)))\n",
        "    X = X @ R\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X, y = make_sunny_moons(n_sun=150, n_moons=300, noise=0.15)\n",
        "_ = plt.figure(figsize=(6, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='cool')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3tXhpQ9GBdhV"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def make_clf_plot(classifier, axis):\n",
        "    classifier.fit(X, y)\n",
        "    plot_decision_regions(X, y, clf=classifier, legend=2, ax=axis)\n",
        "    accuracy = accuracy_score(y, classifier.predict(X))\n",
        "    axis.set_title(f\"{classifier.__class__.__name__}, accuracy = {accuracy:2.2f}\")\n",
        "\n",
        "\n",
        "_ = plt.figure(figsize=(6, 6))\n",
        "axis = plt.axes()\n",
        "clf = MyAdaBoostClassifier(n_estimators=10, base_estimator=DecisionTreeClassifier, max_depth=3, seed=42)\n",
        "make_clf_plot(clf, axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEWdixsrBdhV"
      },
      "source": [
        "Теперь посмотрим на процесс обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wX8DacnlBdhW"
      },
      "outputs": [],
      "source": [
        "plt.plot(clf.error_history)\n",
        "plt.title('Weighted errors for sequentially learned estimators')\n",
        "plt.xlabel('estimator index')\n",
        "plt.ylabel('weighted error')\n",
        "plt.show()\n",
        "print(f'Last estimator weighted error is {clf.error_history[-1]:0.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg_Njvy3BdhW"
      },
      "source": [
        "Видим, что ошибка последнего близка к нулю. Предположите, как будет изменяться ошибка при добавлении большего числа базовых классификаторов? \\\n",
        "Давайте теперь проверим ваше предположение!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6kT3F_x4BdhX"
      },
      "outputs": [],
      "source": [
        "clf = MyAdaBoostClassifier(n_estimators=20, base_estimator=DecisionTreeClassifier, max_depth=3, seed=42)\n",
        "clf.fit(X, y)\n",
        "plt.plot(clf.error_history)\n",
        "plt.title('Weighted errors for sequentially learned estimators')\n",
        "plt.xlabel('estimator index')\n",
        "plt.ylabel('weighted error')\n",
        "plt.show()\n",
        "print(f'Last estimator weighted error is {clf.error_history[-1]:0.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz6NHmJfBdhX"
      },
      "source": [
        "Попытайтесь объяснить, почему так происходит?\n",
        "\n",
        "<details>\n",
        "\n",
        "  <summary><b>Нажмите однократно, чтобы раскрыть</b></summary>\n",
        "\n",
        "Поскольку это взвешенная ошибка последнего классификатора, как только мы выучиваем какую-то группу тяжелых примеров, они начинают предсказываться корректно и больший вклад начинают делать примеры, которым мы на данном шаге не уделили внимания. В целом error_rate слабых классификаторов и не должен сходится к нулю, но их ансамбль работает на порядок лучше из-за разнообразия, что мы и видели выше на близкой к 1 accuracy.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tUeww_2BdhX"
      },
      "source": [
        "Сравните такой взвешенный ансамбль деревьев со случайным лесом из `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0INEeObWBdhY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(13, 6.5))\n",
        "\n",
        "for classifier, axis in zip(\n",
        "        (\n",
        "            # put models (Boosting and Forest) with equivalent parameters for trees (e.g. max_depth=3/4, etc)\n",
        "            # see example with GaussianNB model below \n",
        "        ), axes):\n",
        "    make_clf_plot(classifier, axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faPi-QvKBdhY"
      },
      "source": [
        "Видим, что несмотря на одинаковое количество разделяющих сегментов (поскольку количество и глубина деревьев зафиксированы), бустинг справляется с классификацией сильно лучше, особенно на сложных примерах, где данные нелинейны и находятся близко друг к другу. Однако такая гибкость может привести к переобучению:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qudK3i9DBdhY"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(13, 6.5))\n",
        "\n",
        "for classifier, axis in zip(\n",
        "        (\n",
        "            # put here both models with many estimators\n",
        "        ), axes):\n",
        "    make_clf_plot(classifier, axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyqbyPEWBdhY"
      },
      "source": [
        "В зависимости от сида и удачи, вы можете поймать моменты, когда адаптивный бустинг рисует островки одного класса внутри региона другого, что является одним из хороших признаков переобучения, причем все это на трейне! Поэтому число эстиматоров надо тюнить и смотреть на метрики на тесте."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_jb78F6BdhZ"
      },
      "source": [
        "Теперь попробуем забустить логистическую регрессию, чтобы порадоваться какой мощный метод мы заимплементировали."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SI7MYHw7BdhZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(13, 6.5))\n",
        "\n",
        "for classifier, axis in zip(\n",
        "        (\n",
        "            # Boost logistic regression and plot alongside with just one logreg, regularize it slightly\n",
        "        ), axes):\n",
        "    make_clf_plot(classifier, axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZoO48m5BdhZ"
      },
      "source": [
        "Видим, что качество очень далеко от ожидаемого, что же случилось?\n",
        "\n",
        "<details>\n",
        "\n",
        "  <summary><b>Нажмите однократно, чтобы раскрыть</b></summary>\n",
        "\n",
        "Поскольку предсказание формируется из линейной комбинации скоров базовых моделей (см формулу выше), мы все равно получаем линейную модель, которая не может разделить нелинейную выборку и профита от бустинга нет..\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avA4qHszBdhZ"
      },
      "source": [
        "Применим другую модель послабее, зато нелинейную, которая предсказывает гауссовы центроиды"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CMK07_KeBdhZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(13, 6.5))\n",
        "\n",
        "for classifier, axis in zip(\n",
        "        (\n",
        "                MyAdaBoostClassifier(n_estimators=30, base_estimator=GaussianNB, seed=42),\n",
        "                GaussianNB()\n",
        "\n",
        "        ), axes):\n",
        "    make_clf_plot(classifier, axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fnAtFGWBdha"
      },
      "source": [
        "Отлично, с адаптивным бустингом разобрались, теперь давайте имплементируем знаменитый градиентный бустинг.\n",
        "\n",
        "#### Градиентный бустинг\n",
        "Идея градиентного бустинга заключается в том, чтобы выполнить дискретную градиентную оптимизацию какой-нибудь выпуклой функции потерь, предсказывая на каждом шагу градиент специально обученным **регрессором**. Другая точка зрения состоит в том, что каждая последующая модель бустинга учится предсказывать отклонение ансамбля предыдущих от правильного значения, так что они постепенно уточняют итоговый предикт. \\\n",
        "Алгоритм градиентного бустинга можно прочитать в [учебнике](https://ml-handbook.ru/chapters/grad_boost/intro). Наша реализация будет иметь следующие особенности:\n",
        "* Поскольку модели учатся предсказывать градиент, то вместо базовых классификаторов нам потребуются базовые **регрессоры**, мы используем регрессионные деревья из `sklearn`\n",
        "* Константный лернинг рейт (гамма) для борьбы с переобучением и упрощения реализации\n",
        "* Будет реализована только бинарная классификация, поскольку градиент по предсказаниям модели в случае многоклассовой классификации — это вектор по числу классов, нам потребуется `К` регрессионных деревьев на каждом шаге (каждое из них умеет предсказывать только одно число). Держите это в голове, когда используете градиентный бустинг из `sklearn`: в нем число деревьев, из которых состоит модель, на самом деле равно число_классов * `n_estimators`. Для бинарного случая такой проблемы нет, поскольку достаточного одного числа для предсказания бинарной вероятности\n",
        "* Наша имплементация опирается на логиты — сырые предсказания регрессионной модели, принимающие вещественные значения. Вероятности из них по аналогии с логистической регрессией будем получать при помощи сигмоиды\n",
        "* В качестве функции потерь возьмем отрицательное лог-правдоподобие. Объединяя с пунктом выше имеем такие формулы:\n",
        "$$\n",
        "    \\text{model}(x) = h, \\ \\text{probability} = \\sigma(h) \\\\\n",
        "    \\mathcal{L}(\\text{model}, X, Y) = -\\sum_{(x, y) \\in X\\oplus Y} y \\cdot\\log(\\text{probability}(\\text{model}(x))) + (1 - y) \\cdot \\log(1 - \\text{probability}(\\text{model}(x)))\n",
        "$$\n",
        "\n",
        "**4. (1 балл) Сдайте реализацию функции потерь в градиентном бустинге в контест.**\n",
        "\n",
        "**5. (2 балла) Сдайте реализацию обучения классификатора в контест.**\n",
        "\n",
        "**6. (2 балла) Сдайте реализацию предсказания в градиентном бустинге в контест.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B0a8ISpvBdha"
      },
      "outputs": [],
      "source": [
        "from src import MyBinaryTreeGradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "A7nDRqmPBdha"
      },
      "outputs": [],
      "source": [
        "X, y = make_moons(n_samples=300, noise=0.15, random_state=42)\n",
        "\n",
        "\n",
        "def make_clf_plot(classifier, axis):\n",
        "    classifier.fit(X, y)\n",
        "    plot_decision_regions(X, y, clf=classifier, legend=2, ax=axis)\n",
        "    accuracy = accuracy_score(y, classifier.predict(X))\n",
        "    axis.set_title(f\"{classifier.__class__.__name__}, accuracy = {accuracy:2.2f}\")\n",
        "\n",
        "\n",
        "_ = plt.figure(figsize=(6, 6))\n",
        "axis = plt.axes()\n",
        "clf = MyBinaryTreeGradientBoostingClassifier(n_estimators=10, learning_rate=1.0, seed=42, max_depth=4)\n",
        "make_clf_plot(clf, axis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdbX9HbtBdha"
      },
      "source": [
        "Посмотрим на перфоманс нашей модели с  точки зрения функции потерь (должна глобально убывать)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "acbIAspLBdha"
      },
      "outputs": [],
      "source": [
        "plt.plot(clf.loss_history)\n",
        "plt.title('LogLoss for sequentially learned estimators')\n",
        "plt.xlabel('estimator index')\n",
        "plt.ylabel('negative log-likelihood')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQIuppIhBdha"
      },
      "source": [
        "Пронаблюдаем зависимость обучения и переобучения от лернинг рейта"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MPTdDiACBdhb"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(6 * 2 + 1, 6 * 3 + 1))\n",
        "\n",
        "def plot_loss(classifier, axis):\n",
        "    axis.plot(classifier.loss_history)\n",
        "    axis.set_title(f'LogLoss for sequentially learned estimators for lr={classifier.learning_rate}')\n",
        "    axis.set_xlabel('estimator index')\n",
        "    axis.set_ylabel('negative log-likelihood')\n",
        "\n",
        "for classifier, axis in zip(\n",
        "        (\n",
        "            # put three different learning rates\n",
        "        ), axes):\n",
        "    make_clf_plot(classifier, axis[0])\n",
        "    plot_loss(classifier, axis[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuqSu2H_Bdhb"
      },
      "source": [
        "Видим, что модель почти не переобучается, и даже при плохих значениях лернинг рейта пытается что-то предсказать. Что будет, если менять число эстиматоров?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HuAr_WZ4Bdhb"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(6 * 2 + 1, 6 * 3 + 1))\n",
        "\n",
        "for classifier, axis in zip(\n",
        "        (\n",
        "            # put three different estimator counts\n",
        "        ), axes):\n",
        "    make_clf_plot(classifier, axis[0])\n",
        "    plot_loss(classifier, axis[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvon0opxBdhb"
      },
      "source": [
        "Видим, что есть некоторый трейд-офф между величиной градиентного шага и количеством таких шагов (что очень похоже на случай линейных моделей). В целом, поскольку шаг бустинга при больших деревьях может выполняться долго, есть смысл оставлять число эстиматоров разумным и тюнить лернинг рейт, который не влияет на скорость работы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQWv70sfBdhb"
      },
      "source": [
        "Насколько предикторы в градиентном бустинге равны между собой (такое любят спрашивать на собеседованиях). Давайте испортим самую первую и самую последнюю базовую модель в наших классификаторах. Подумайте, как в такой ситуации поведет себя адаптивный бустинг."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DQSMKfjaBdhb"
      },
      "outputs": [],
      "source": [
        "class ModelPredictingNoise:\n",
        "    def predict(self, X):\n",
        "        ...\n",
        "        return random_predictions\n",
        "    def predict_proba(self, X):\n",
        "        ...\n",
        "        return random_noise\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(6 * 2 + 1, 6 + 1))\n",
        "for classifier, axis, spoil_id in zip(\n",
        "        (\n",
        "                MyBinaryTreeGradientBoostingClassifier(n_estimators=5, learning_rate=1.0, seed=42, max_depth=4),\n",
        "                MyBinaryTreeGradientBoostingClassifier(n_estimators=5, learning_rate=1.0, seed=42, max_depth=4)\n",
        "        ), axes, [0, -1]):\n",
        "    classifier.fit(X, y)\n",
        "    classifier.estimators[spoil_id] = ModelPredictingNoise()\n",
        "    plot_decision_regions(X, y, clf=classifier, legend=2, ax=axis)\n",
        "    accuracy = accuracy_score(y, classifier.predict(X))\n",
        "    axis.set_title(f\"{classifier.__class__.__name__}, accuracy = {accuracy:2.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0fdyW44Bdhb"
      },
      "source": [
        "Видим, что при достаточно больших значениях лернинг рейта, уточняющие модели дают ощутимый вклад, но все равно, первое дерево дает более весомый вклад в ответ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM-v8KJ2Bdhb"
      },
      "source": [
        "#### Теперь в лабе можно пользоваться лучшей общедоступной реализацией бустинга CatBoost, ура :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yp38gIESBdhc"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hISYm4NBdhc"
      },
      "source": [
        "Вернемся к нашей задаче с классификацией музыки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-idtz1MkBdhc"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d purumalgi/music-genre-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HQeWs0eqBdhc"
      },
      "outputs": [],
      "source": [
        "!unzip music-genre-classification.zip -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JCvgvHj9Bdhc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_csv = pd.read_csv('./data/train.csv')\n",
        "test_csv = pd.read_csv('./data/test.csv')\n",
        "submission_csv = pd.read_csv('./data/submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HU_F2k2mBdhc"
      },
      "outputs": [],
      "source": [
        "train_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NyFKc5rQBdhc"
      },
      "outputs": [],
      "source": [
        "test_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LiDYLUDGBdhc"
      },
      "outputs": [],
      "source": [
        "submission_csv.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezcj_ZQCBdhc"
      },
      "source": [
        "В прошлый раз мы пытались предсказать жанр музыки основываясь только на вещественных фичах, которые способны были скушать наши деревья, но поскольку мы обладаем теперь более мощными моделями, давайте сделаем более мощные фичи. Тем более что это очень просто с катбустом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcqZkX3qBdhc"
      },
      "source": [
        "Напомним наш прошлый топовый пайплайн без учета стэкинга. **Положите рядом с ноутбуком пикл индексов для разбиения из прошлой домашки, а также логи хэндлера экспериментов, чтобы продолжить существующий лидерборд.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LTh2eCdWBdhc"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "filename = 'indices.pckl'\n",
        "if os.path.exists(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        indices = pickle.load(f)\n",
        "else:\n",
        "    indices = {}\n",
        "    indices['train_indices'], indices['test_indices'] = train_test_split(\n",
        "        np.arange(len(train_csv)),\n",
        "        test_size=2996,\n",
        "        stratify=train_csv['Class'],\n",
        "        shuffle=True,\n",
        "        random_state=0xBA0BAB\n",
        "    )\n",
        "\n",
        "    train_df = train_csv.iloc[indices['train_indices']]\n",
        "    cv_splitter = StratifiedKFold(\n",
        "        n_splits=3,\n",
        "        shuffle=True,\n",
        "        random_state=0xBED\n",
        "    )\n",
        "    indices['cv_iterable'] = []\n",
        "    for train_indices, val_indices in cv_splitter.split(train_df.drop('Class', axis=1), train_df['Class']):\n",
        "        indices['cv_iterable'].append(\n",
        "            (train_indices, val_indices)\n",
        "        )\n",
        "    with open(filename, 'wb+') as f:\n",
        "        pickle.dump(indices, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "osKp23UxBdhd"
      },
      "outputs": [],
      "source": [
        "train_indices = indices['train_indices']\n",
        "test_indices = indices['test_indices']\n",
        "cv_iterable = indices['cv_iterable']\n",
        "X_train = train_csv.iloc[train_indices].drop('Class', axis=1)\n",
        "y_train = train_csv.iloc[train_indices]['Class']\n",
        "X_test = train_csv.iloc[test_indices].drop('Class', axis=1)\n",
        "y_test = train_csv.iloc[test_indices]['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KeWTYSX3Bdhd"
      },
      "outputs": [],
      "source": [
        "from src import Logger, ExperimentHandler\n",
        "\n",
        "logger = Logger('./logs')\n",
        "scorer = ExperimentHandler(\n",
        "    X_train, y_train, X_test, y_test, cv_iterable, logger,\n",
        "    metrics={\n",
        "        'BalancedAccuracy': 'balanced_accuracy',\n",
        "        'NegLogLoss': 'neg_log_loss'\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OswMoaOOBdhd"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest_pipeline = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            'extract numeric features',\n",
        "            ColumnTransformer(\n",
        "                [\n",
        "                    (\n",
        "                        'drop words',\n",
        "                        'drop',\n",
        "                        ['Artist Name', 'Track Name']\n",
        "                    )\n",
        "                ],\n",
        "                remainder='passthrough'\n",
        "            )\n",
        "        ),\n",
        "        (\n",
        "            'fill missing values',\n",
        "            SimpleImputer(strategy='constant', fill_value=X_train.apply(pd.to_numeric, errors='coerce').max().max())\n",
        "        ),\n",
        "        (\n",
        "            'estimator',\n",
        "            RandomForestClassifier(n_estimators=200, random_state=0x5EED)\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk9d3A1dBdhd"
      },
      "source": [
        "Попробуем в нашем пайплайне применить бустинг и померить профит"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "V9gbjPXtBdhd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradboost_pipeline = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            'extract numeric features',\n",
        "            ColumnTransformer(\n",
        "                [\n",
        "                    (\n",
        "                        'drop words',\n",
        "                        'drop',\n",
        "                        ['Artist Name', 'Track Name']\n",
        "                    )\n",
        "                ],\n",
        "                remainder='passthrough'\n",
        "            )\n",
        "        ),\n",
        "        (\n",
        "            'fill missing values',\n",
        "            SimpleImputer(strategy='constant', fill_value=X_train.apply(pd.to_numeric, errors='coerce').max().max())\n",
        "        ),\n",
        "        (\n",
        "            'estimator',\n",
        "            GradientBoostingClassifier(n_estimators=50, random_state=0x5EED)\n",
        "            # это 50 * 11 деревьев, тк у нас 11 классов\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fXQkKWTJBdhd"
      },
      "outputs": [],
      "source": [
        "scorer.logger.leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rrnVWF87Bdhd"
      },
      "outputs": [],
      "source": [
        "scorer.run(gradboost_pipeline, name='gradboost_on_old_features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JLhS7Ze-Bdhd"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "catboost_pipeline = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            'extract numeric features',\n",
        "            ColumnTransformer(\n",
        "                [\n",
        "                    (\n",
        "                        'drop words',\n",
        "                        'drop',\n",
        "                        ['Artist Name', 'Track Name']\n",
        "                    )\n",
        "                ],\n",
        "                remainder='passthrough'\n",
        "            )\n",
        "        ),\n",
        "        (\n",
        "            'fill missing values',\n",
        "            SimpleImputer(strategy='constant', fill_value=X_train.apply(pd.to_numeric, errors='coerce').max().max())\n",
        "        ),\n",
        "        (\n",
        "            'estimator',\n",
        "            CatBoostClassifier(iterations=200, random_state=0x5EED)\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nzg73lySBdhe"
      },
      "outputs": [],
      "source": [
        "scorer.run(catboost_pipeline, name='catboost_on_old_features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFaA-QCWBdhe"
      },
      "source": [
        "(Катбуст пока не побеждает)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNYt2ceLBdhe"
      },
      "source": [
        "Видим, что в нашем пайплайне мы отказались от важного набора фичей — текстовых фичей. Почему они могут нам докинуть качества:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_EiMLfaoBdhe"
      },
      "outputs": [],
      "source": [
        "intersection_of_artists = # найдите пересечение между артистами из терйна и теста\n",
        "print(\"Example of overlap between artist names from train and test\")\n",
        "print(list(intersection_of_artists)[:10])\n",
        "print('Count of overlapping artists:', len(intersection_of_artists))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZb2bmRDBdhe"
      },
      "source": [
        "Проверим предположение, что исполнители в среднем играют музыку в одном и том же жанре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "J8mKy4A0Bdhe"
      },
      "outputs": [],
      "source": [
        "track_genre_per_artist_counts = X_train.join(y_train)[['Artist Name', 'Class']].groupby(['Artist Name', 'Class']).agg(\n",
        "    count_col=pd.NamedAgg(column=\"Class\", aggfunc=\"count\")\n",
        ")\n",
        "track_genre_per_artist_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiODCby8Bdhe"
      },
      "source": [
        "Посмотрим, сколько артистов с более чем одним жанром, сколько у них трэков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F4RM7GxWBdhe"
      },
      "outputs": [],
      "source": [
        "print('Count of unique artists:', X_train['Artist Name'].nunique())\n",
        "print('Count of artists with more than two genres:',\n",
        "      (track_genre_per_artist_counts.groupby(level=0).count() > 1).sum().item())\n",
        "top_represented_tracks_count = track_genre_per_artist_counts.groupby(level=0)['count_col'].max()\n",
        "print('Mean value of top-repesented genre tracks count:', top_represented_tracks_count.mean())\n",
        "print('Max value of top-repesented genre tracks count:', top_represented_tracks_count.max())\n",
        "plt.bar(x=np.arange(top_represented_tracks_count.shape[0]),\n",
        "        height=top_represented_tracks_count.sort_values(ascending=False))\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unorsr7xBdhe"
      },
      "source": [
        "Интуитивно кажется, что примеров одножанровых артистов не так много, особенно, учитывая, что оверлап с тестом не такой большой. Но они есть и надо засунуть их в модель, чтобы понять какой профит будет от этого. Только вопрос, как это сделать. Если, допустим, трактовать имя исполнителя, как категориальную фичу, то ординальность получится более 8к, а значит никакого one-hot кодирования сделать не получится. У нас будет очень разреженная фича, задача получится переопределенной и потребуется модель с большой \"емкостью\", чтобы запомнить, какой категории соответствует какой таргет. В этом месте у нас два пути: работать с фичей как с текстовой или использовать другие способы кодирования, научимся делать оба!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyrUwh-GBdhf"
      },
      "source": [
        "Первый вариант, закодировать таргетом, добавив для теста вариант фичи \"не встречалась в трейне\", напишите соответствующий кодировщик средствами `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3-CYKWFaBdhf"
      },
      "outputs": [],
      "source": [
        "artist_top_genre_tuples = track_genre_per_artist_counts.groupby(level=0).idxmax()['count_col'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0eIblL5dBdhf"
      },
      "outputs": [],
      "source": [
        "dict(artist_top_genre_tuples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LuTVk89eBdhf"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "class SimpleTargetEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.dict_of_artists = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = pd.DataFrame(X, columns=X_train.columns)\n",
        "        if isinstance(y, pd.Series):\n",
        "            X['Class'] = y.values\n",
        "        elif isinstance(y, np.ndarray):\n",
        "            X['Class'] = y\n",
        "        track_genre_per_artist_counts = # подсчитайте сколько треков данного артиста принадлежат данному жанру\n",
        "        artist_top_genre_tuples = # постройте словарь для реплейса\n",
        "        self.dict_of_artists = dict(artist_top_genre_tuples)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.DataFrame(X, columns=X_train.columns)\n",
        "        X['Target Encoded Artists'] = X['Artist Name'].map(self.dict_of_artists).fillna(value=-1).astype(int)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wTLBLC3BBdhf"
      },
      "outputs": [],
      "source": [
        "tr = SimpleTargetEncoder()\n",
        "tr.fit(X_train, y_train).transform(X_train).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ju2bY1hHBdhf"
      },
      "outputs": [],
      "source": [
        "tr.transform(X_test).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkkS9qdkBdhf"
      },
      "source": [
        "Теперь такую категориальную фичу можно преобразовать в OneHot и использовать в пайлпайне"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "64GTw58pBdhf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "catboost_pipeline = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            'target encode',\n",
        "            ColumnTransformer(\n",
        "                [\n",
        "                    (\n",
        "                        'Target Encode Artist Name',\n",
        "                        SimpleTargetEncoder(),\n",
        "                        X_train.columns\n",
        "                    )\n",
        "                ],\n",
        "            )\n",
        "        ),\n",
        "        (\n",
        "            'extract numeric features',\n",
        "            ColumnTransformer(\n",
        "                [\n",
        "                    (\n",
        "                        'OHE for target encoded artist names',\n",
        "                        OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
        "                        [16, ] # those magic numbers are used to overcome issue with improper handling of dataframes by column transformer\n",
        "                    ),\n",
        "                    (\n",
        "                        'drop words',\n",
        "                        'drop',\n",
        "                        [0, 1]  # those magic numbers are used to overcome issue with improper handling of dataframes by column transformer\n",
        "                    )\n",
        "                ],\n",
        "                remainder='passthrough'\n",
        "            )\n",
        "        ),\n",
        "        (\n",
        "            'fill missing values',\n",
        "            SimpleImputer(strategy='constant', fill_value=X_train.apply(pd.to_numeric, errors='coerce').max().max())\n",
        "        ),\n",
        "        (\n",
        "            'estimator',\n",
        "            CatBoostClassifier(iterations=200, random_state=0x5EED)\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_daqJQQBBdhf"
      },
      "outputs": [],
      "source": [
        "scorer.run(catboost_pipeline, name='catboost_on_simple_target_encoded_features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCe76ZV8Bdhg"
      },
      "source": [
        "Стало сильно лучше!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "15OQQCNYBdhg"
      },
      "outputs": [],
      "source": [
        "scorer.logger.leaderboard.sort_values(by='BalancedAccuracy_test', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTplQKCqBdhg"
      },
      "source": [
        "На самом деле нет необходимости кодировать текстовые фичи мануально — ведь катбуст может работать с текстовыми из коробки, для этого он применяет Bag of Words/TF-IDF методы. Поскольку ключевые слова из названий исполнителей и песен могут нести положительный сигнал, мы ожидаем прирост качества от этого подхода. А еще, как следует из названия, он поддерживает категориальные фичи множеством разных методов их кодирования. Воспользуйтесь этим и постройте сильную модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DkwxtrgWBdhg"
      },
      "outputs": [],
      "source": [
        "class PandasSimpleImputer(SimpleImputer):\n",
        "    \"\"\"\n",
        "    A wrapper around `SimpleImputer` to return data frames with columns.\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns = X.columns\n",
        "        return super().fit(X, y)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return pd.DataFrame(super().transform(X), columns=self.columns)\n",
        "\n",
        "strong_catboost_pipeline = Pipeline(\n",
        "    [\n",
        "        (\n",
        "            'fill missing values',\n",
        "            PandasSimpleImputer(strategy='constant', fill_value=X_train.apply(pd.to_numeric, errors='coerce').max().max())\n",
        "        ),\n",
        "        (\n",
        "            'estimator',\n",
        "            CatBoostClassifier(SOMETHING) # разберитесь в параметрах катбуста, чтобы он обучался на текстовых и категориальных фичах\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "As3hp-NxBdhg"
      },
      "outputs": [],
      "source": [
        "strong_catboost_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUlKWDB6Bdhg"
      },
      "source": [
        "Проверим только качество на тесте, чтобы не ждать, когда катбуст обучится на всех фолдах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "H7Os4xOABdhg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "predictions = strong_catboost_pipeline.predict(X_test)\n",
        "print('strong catboost balanced accuracy on test:', balanced_accuracy_score(y_test, predictions))\n",
        "print('top balanced accuracy from our previous results is:', scorer.logger.leaderboard['BalancedAccuracy_test'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PyE7D60Bdhg"
      },
      "source": [
        "Отрефлексируйте полученный результат."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}